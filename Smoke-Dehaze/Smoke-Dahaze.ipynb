{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47cb02e",
   "metadata": {},
   "source": [
    "\n",
    "# Thermal Person Detector — YOLOv8 (Clean, Portable Notebook)\n",
    "**KR**: 이 노트북은 열화상 이미지에서 사람을 탐지하는 YOLOv8 워크플로우를 재현 가능한 형태로 제공합니다.  \n",
    "Colab 전용이 아니라 로컬(Windows/macOS/Linux) 또는 다른 환경에서도 그대로 실행할 수 있도록 구성했습니다.\n",
    "\n",
    "**EN**: This notebook provides a reproducible YOLOv8 workflow for detecting people in thermal images.  \n",
    "It is designed to run anywhere (local Windows/macOS/Linux or other environments), not just on Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2e869",
   "metadata": {},
   "source": [
    "\n",
    "## Contents / 목차\n",
    "1. Environment Setup (로컬 실행 준비)  \n",
    "2. Project Structure & Paths (프로젝트 구조와 경로)  \n",
    "3. (Optional) Dataset Preparation (선택) 데이터셋 준비  \n",
    "4. Quick Inference with Existing Weights (가중치로 바로 추론)  \n",
    "5. (Optional) Training (선택) 학습  \n",
    "6. Export to ONNX (ONNX로 내보내기)  \n",
    "7. ONNX Sanity Check (ONNX 무결성/드라이런 확인)  \n",
    "8. (Optional) TFLite Conversion (선택) TFLite 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac7c90",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Environment Setup / 로컬 실행 준비\n",
    "**KR**: 아래 셀은 필수 패키지를 설치하고, 환경 정보를 확인합니다.  \n",
    "**EN**: The cell below installs required packages and prints environment info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're on a managed environment, you may skip installs that are already satisfied.\n",
    "# 필요시만 설치하세요. (Ultralytics, ONNX, ONNXRuntime)\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(package):\n",
    "    try:\n",
    "        __import__(package.split(\"==\")[0].replace(\"-\", \"_\"))\n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Minimal dependencies (pin lightly if needed)\n",
    "for pkg in [\"ultralytics>=8.2.0\", \"onnx>=1.15.0\", \"onnxruntime>=1.17.0\", \"opencv-python>=4.7.0\", \"numpy>=1.26.0\"]:\n",
    "    pip_install(pkg)\n",
    "\n",
    "import platform, torch, onnx, onnxruntime as ort, cv2, numpy as np\n",
    "import ultralytics\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Torch:\", torch.__version__, \"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"Ultralytics:\", ultralytics.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"ONNX:\", onnx.__version__)\n",
    "print(\"ONNXRUNTIME:\", ort.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc0480",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Project Structure & Paths / 프로젝트 구조와 경로\n",
    "**KR**: 프로젝트 루트와 입출력 경로를 지정합니다. OS에 관계없이 동작하도록 `os.path`를 사용합니다.  \n",
    "**EN**: Define root and I/O paths. We use `os.path` to be OS-agnostic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# You can change ROOT to where your project lives\n",
    "ROOT = os.path.abspath(\".\")\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")          # your dataset root (images/, labels/)\n",
    "WEIGHTS_DIR = os.path.join(ROOT, \"weights\")    # store trained / downloaded weights\n",
    "EXPORT_DIR = os.path.join(ROOT, \"export\")      # exported ONNX etc.\n",
    "RESULTS_DIR = os.path.join(ROOT, \"results\")    # inference outputs\n",
    "\n",
    "for d in [DATA_DIR, WEIGHTS_DIR, EXPORT_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"WEIGHTS_DIR:\", WEIGHTS_DIR)\n",
    "print(\"EXPORT_DIR:\", EXPORT_DIR)\n",
    "print(\"RESULTS_DIR:\", RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c617a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) (Optional) Dataset Preparation / (선택) 데이터셋 준비\n",
    "**KR**: YOLO 형식의 데이터셋(`images/train|val`, `labels/train|val`, `.yaml`)을 사용합니다.  \n",
    "이미 준비된 `.yaml`이 있다면, 경로만 맞추면 됩니다.  \n",
    "**EN**: We use a standard YOLO dataset layout. If you already have a `.yaml`, set correct paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb34f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example YAML template generator (edit paths/classes as needed)\n",
    "yaml_path = os.path.join(DATA_DIR, \"thermal_person.yaml\")\n",
    "yaml_text = f\"\"\"\n",
    "# YOLO dataset YAML for thermal person detection\n",
    "path: {DATA_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: person\n",
    "\"\"\"\n",
    "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(\"Wrote dataset YAML ->\", yaml_path)\n",
    "print(\"Edit it as needed to match your folder structure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ee688",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Quick Inference with Existing Weights / 가중치로 바로 추론\n",
    "**KR**: 이미 학습된 가중치(.pt 또는 .engine 등)가 있다면, 아래처럼 즉시 추론을 실행합니다.  \n",
    "**EN**: If you have pre-trained weights (.pt), run quick inference as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab871f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import glob\n",
    "\n",
    "# Point to an existing .pt (replace with your actual file)\n",
    "candidate_pts = glob.glob(os.path.join(WEIGHTS_DIR, \"*.pt\"))\n",
    "if candidate_pts:\n",
    "    weights_path = candidate_pts[0]\n",
    "else:\n",
    "    # Download a small model if none found (you can change to 'yolov8n.pt' / 'yolov8n-seg.pt', etc.)\n",
    "    weights_path = os.path.join(WEIGHTS_DIR, \"yolov8n.pt\")\n",
    "    if not os.path.exists(weights_path):\n",
    "        model = YOLO(\"yolov8n.pt\")\n",
    "        model.export(format=\"pt\")  # this will download weights into a temp dir; we just keep using hub weights\n",
    "        # Alternatively, save a local copy\n",
    "        import shutil\n",
    "        src = model.ckpt_path if hasattr(model, \"ckpt_path\") else None\n",
    "        if src and os.path.exists(src):\n",
    "            shutil.copy(src, weights_path)\n",
    "\n",
    "print(\"Using weights:\", weights_path)\n",
    "\n",
    "# Input image(s)\n",
    "SAMPLE_IMG = os.path.join(DATA_DIR, \"sample.jpg\")  # replace with your thermal image\n",
    "if not os.path.exists(SAMPLE_IMG):\n",
    "    # Create a dummy image if missing\n",
    "    import numpy as np, cv2\n",
    "    dummy = np.zeros((256,256,3), dtype=np.uint8)\n",
    "    cv2.putText(dummy, \"Place thermal image here\", (10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    cv2.imwrite(SAMPLE_IMG, dummy)\n",
    "\n",
    "# Run inference\n",
    "model = YOLO(weights_path)\n",
    "res = model.predict(source=SAMPLE_IMG, save=True, project=RESULTS_DIR, name=\"infer_once\", imgsz=640, conf=0.25)\n",
    "print(\"Result dir:\", os.path.join(RESULTS_DIR, \"infer_once\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f0a7ed",
   "metadata": {},
   "source": [
    "\n",
    "## 5) (Optional) Training / (선택) 학습\n",
    "**KR**: 학습은 데이터셋이 준비되어 있을 때만 실행하세요. 빠른 데모를 위해 작은 epoch로 설정되어 있습니다.  \n",
    "**EN**: Run training only if your dataset is ready. We keep epochs small for a quick demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a small model (edit hyperparameters as needed)\n",
    "# NOTE: You must have DATA_DIR/images/train & labels/train ready.\n",
    "do_train = False  # set True to train\n",
    "\n",
    "if do_train:\n",
    "    model = YOLO(\"yolov8n.pt\")  # or a custom base\n",
    "    model.train(\n",
    "        data=os.path.join(DATA_DIR, \"thermal_person.yaml\"),\n",
    "        epochs=5,\n",
    "        imgsz=640,\n",
    "        batch=8,\n",
    "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "        project=os.path.join(ROOT, \"runs\"),\n",
    "        name=\"thermal_yolov8_demo\",\n",
    "        seed=42\n",
    "    )\n",
    "    # Save trained weights to WEIGHTS_DIR\n",
    "    last = os.path.join(ROOT, \"runs\", \"detect\", \"thermal_yolov8_demo\", \"weights\", \"last.pt\")\n",
    "    best = os.path.join(ROOT, \"runs\", \"detect\", \"thermal_yolov8_demo\", \"weights\", \"best.pt\")\n",
    "    if os.path.exists(best):\n",
    "        import shutil\n",
    "        shutil.copy(best, os.path.join(WEIGHTS_DIR, \"best.pt\"))\n",
    "        print(\"Copied best.pt ->\", os.path.join(WEIGHTS_DIR, \"best.pt\"))\n",
    "    elif os.path.exists(last):\n",
    "        shutil.copy(last, os.path.join(WEIGHTS_DIR, \"last.pt\"))\n",
    "        print(\"Copied last.pt ->\", os.path.join(WEIGHTS_DIR, \"last.pt\"))\n",
    "else:\n",
    "    print(\"Training skipped. Set do_train=True to enable training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6b441",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Export to ONNX / ONNX로 내보내기\n",
    "**KR**: 추론용 가중치(.pt)를 ONNX로 변환합니다. opset, dynamic batch 등의 옵션을 노출했습니다.  \n",
    "**EN**: Convert .pt weights to ONNX. We expose opset and dynamic options commonly needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Choose which weights to export (existing or just used above)\n",
    "export_src = candidate_pts[0] if 'candidate_pts' in globals() and candidate_pts else os.path.join(WEIGHTS_DIR, \"yolov8n.pt\")\n",
    "print(\"Export source:\", export_src)\n",
    "\n",
    "model = YOLO(export_src)\n",
    "onnx_out = os.path.join(EXPORT_DIR, \"model.onnx\")\n",
    "model.export(format=\"onnx\", opset=12, dynamic=True, imgsz=640, half=False)  # Ultralytics writes to its own path\n",
    "\n",
    "# Find the exported ONNX (Ultralytics typically names it automatically in the working dir)\n",
    "# We'll search for the newest .onnx under EXPORT_DIR or ROOT\n",
    "import glob, time\n",
    "candidates = glob.glob(os.path.join(ROOT, \"**\", \"*.onnx\"), recursive=True)\n",
    "candidates = sorted(candidates, key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "if candidates:\n",
    "    latest_onnx = candidates[0]\n",
    "    # Copy to EXPORT_DIR/model.onnx\n",
    "    import shutil\n",
    "    shutil.copy(latest_onnx, onnx_out)\n",
    "    print(\"Copied ONNX ->\", onnx_out)\n",
    "else:\n",
    "    print(\"No ONNX found. Check export logs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a99038",
   "metadata": {},
   "source": [
    "\n",
    "## 7) ONNX Sanity Check / ONNX 무결성 확인 & 드라이런\n",
    "**KR**: ONNX 모델을 로드해 shape를 확인하고, 임의 입력으로 드라이런합니다.  \n",
    "**EN**: Load the ONNX model, inspect I/O shapes, and run a dry inference with random data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np, os, cv2\n",
    "\n",
    "onnx_path = os.path.join(EXPORT_DIR, \"model.onnx\")\n",
    "assert os.path.exists(onnx_path), f\"ONNX not found: {onnx_path}\"\n",
    "\n",
    "model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(model)\n",
    "print(\"ONNX checked OK\")\n",
    "\n",
    "sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "inputs = sess.get_inputs()\n",
    "outputs = sess.get_outputs()\n",
    "\n",
    "print(\"Inputs:\", [(i.name, i.shape, i.type) for i in inputs])\n",
    "print(\"Outputs:\", [(o.name, o.shape, o.type) for o in outputs])\n",
    "\n",
    "# Make a dummy input that matches the expected shape (usually [1,3,640,640])\n",
    "# If dynamic, convert SAMPLE_IMG to 640x640 and feed as NCHW.\n",
    "img = cv2.imread(SAMPLE_IMG, cv2.IMREAD_COLOR)\n",
    "img = cv2.resize(img, (640, 640), interpolation=cv2.INTER_LINEAR)\n",
    "x = img[:, :, ::-1].transpose(2,0,1).astype(np.float32) / 255.0  # BGR->RGB, HWC->CHW, [0,1]\n",
    "x = np.expand_dims(x, 0)  # [1,3,640,640]\n",
    "\n",
    "feed = {inputs[0].name: x}\n",
    "pred = sess.run([o.name for o in outputs], feed)\n",
    "print(\"ONNX forward OK. Got\", len(pred), \"output(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24edc74",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (Optional) TFLite Conversion / (선택) TFLite 변환\n",
    "**KR**: 아래는 일반적인 PyTorch→ONNX→TFLite 경로가 아닌, Ultralytics의 SavedModel 경유 또는 다른 툴체인을 사용하는 흐름이 필요할 수 있습니다.  \n",
    "프로젝트 요구사항에 따라 변환 툴과 버전을 엄격히 맞추세요.  \n",
    "**EN**: For TFLite, you may need different toolchains or export routes (e.g., SavedModel).  \n",
    "Match the tool versions precisely per your deployment target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a74b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder for TFLite conversion (highly version-sensitive; provide your own pipeline as needed).\n",
    "print(\"TFLite conversion is environment-specific. Add your converter steps here if required.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d71aff",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notes / 비고\n",
    "- **Data & Licenses**: If you're using subsets of public datasets (e.g., Set-A only), clearly state it in your README and follow licenses.  \n",
    "- **Reproducibility**: Pin versions (requirements.txt) and seeds where necessary. Document opset/imgsz/conf/iou/NMS, etc.  \n",
    "- **Portability**: This notebook avoids Colab-only paths/commands. It should run on most machines with Python≥3.9.\n",
    "\n",
    "**Happy building!**\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
